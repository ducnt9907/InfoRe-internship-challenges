import numpy as np
import keras
import cv2
import glob
import functools

from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.optimizers import Adam
from keras.utils import np_utils
from sklearn.model_selection import train_test_split
from PIL import Image as PImage
from os import listdir

from google.colab import drive
drive.mount('/content/drive')

top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)
top3_acc.__name__ = 'top3_acc'
top1_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=1)
top1_acc.__name__ = 'top1_acc'

# Load data
data = []
label = []

def load_image(name,index):
    path = "/content/drive/My Drive/Colab Notebooks/dataset/" + name + "/*JPEG"
    for file in glob.glob(path):
        img = cv2.imread(file) 
        img  = cv2.resize(img,(224,224))
        data.append(img)
        label.append(index)
    return data,label

i=0 
dog_name = ["bullmastiff","chowchow","pug","maltese","huskysibir","dachshund","dalmatian","corgi","chihuahua","yorkshire"]
for name in dog_name:
    print ("loading", i)
    load_image(name,i)
    i +=1

labels = keras.utils.to_categorical(label,10)

# Split test & train data
(trainX, testX, trainY, testY) = train_test_split(np.array(data),np.array(labels), test_size=0.25)

# Use vgg16 model
vgg = keras.applications.vgg16.VGG16(include_top=True, weights="imagenet")

for layer in vgg.layers:
  layer.trainable = False
  
softmax = Dense(10,activation='softmax')(vgg.layers[-2].output)

model = Model(vgg.input,softmax)
model.summary()

# Compile model & train 
opt = Adam(lr=1e-4, decay=1e-3 / 50)
model.compile(loss="categorical_crossentropy", optimizer=opt,
	metrics=["accuracy",top3_acc, top1_acc])
H = model.fit(trainX, trainY, validation_data=(testX, testY),
	epochs=50, batch_size=32)
